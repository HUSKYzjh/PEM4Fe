{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹已存在\n"
     ]
    }
   ],
   "source": [
    "# 创建文件夹\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(\"文件夹创建成功\")\n",
    "    else:\n",
    "        print(\"文件夹已存在\")\n",
    "pwd=\"/home/jhzhai/Nucleation/peek-find/cool700/nc2600\"\n",
    "# pwd=\"/home/jhzhai/Nucleation/peek-find/cool800/nc1600\"\n",
    "# pwd=\"/home/jhzhai/Nucleation/peek-find/cool900/nc1200\"\n",
    "# pwd=\"/home/jhzhai/Nucleation/peek-find/cool1000/nc800\"\n",
    "# pwd=\"/home/jhzhai/Nucleation/peek-find/cool1100/nc600\"\n",
    "create_folder(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹结构已创建\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder structure\n",
    "folder_structure = [\n",
    "    \"PEM4Fe/src\",\n",
    "    \"PEM4Fe/src/__init__.py\",\n",
    "    \"PEM4Fe/src/config.py\",\n",
    "    \"PEM4Fe/src/data_processing.py\",\n",
    "    \"PEM4Fe/src/fitting.py\",\n",
    "    \"PEM4Fe/src/peak_detection.py\",\n",
    "    \"PEM4Fe/src/visualization.py\",\n",
    "    \"PEM4Fe/src/output.py\",\n",
    "    \"PEM4Fe/src/main.py\",\n",
    "    \"PEM4Fe/tests\",\n",
    "    \"PEM4Fe/tests/__init__.py\",\n",
    "    \"PEM4Fe/tests/test_config.py\",\n",
    "    \"PEM4Fe/tests/test_data_processing.py\",\n",
    "    \"PEM4Fe/tests/test_fitting.py\",\n",
    "    \"PEM4Fe/tests/test_peak_detection.py\",\n",
    "    \"PEM4Fe/tests/test_visualization.py\",\n",
    "    \"PEM4Fe/tests/test_output.py\",\n",
    "    \"PEM4Fe/config.json\",\n",
    "    \"PEM4Fe/requirements.txt\",\n",
    "    \"PEM4Fe/README.md\"\n",
    "]\n",
    "\n",
    "# Create the folders and files\n",
    "for path in folder_structure:\n",
    "    if path.endswith('.py') or path.endswith('.json') or path.endswith('.txt') or path.endswith('.md'):\n",
    "        # Create file\n",
    "        with open(path, 'w') as f:\n",
    "            pass\n",
    "    else:\n",
    "        # Create directory\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "print(\"文件夹结构已创建\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是进一步优化代码的建议，整理为列表形式：\n",
    "\n",
    "---\n",
    "\n",
    "### **路径依赖性改进**\n",
    "1. **参数化路径**：\n",
    "   - 使用配置文件（如 JSON、YAML）或命令行参数传递路径，避免硬编码路径。\n",
    "   - 示例：通过 `argparse` 模块让用户在运行脚本时指定路径。\n",
    "2. **动态路径检测**：\n",
    "   - 检测当前运行环境的路径，并根据环境自动调整路径设置。\n",
    "\n",
    "---\n",
    "\n",
    "### **默认参数配置**\n",
    "1. **参数动态调整**：\n",
    "   - 引入基于数据特征的动态参数调整（如根据数据分布自动设置 `width_threshold` 和 `num_density`）。\n",
    "2. **参数文件化**：\n",
    "   - 将所有默认参数放入配置文件，方便统一管理和修改。\n",
    "3. **用户可调参数**：\n",
    "   - 提供命令行或交互界面，让用户动态修改关键参数。\n",
    "\n",
    "---\n",
    "\n",
    "### **性能优化**\n",
    "1. **启用并行处理**：\n",
    "   - 使用 `joblib` 的 `Parallel` 和 `delayed` 并行化对每一列数据的处理。\n",
    "   - 示例：将 `process_column` 调用包裹在 `Parallel` 中处理。\n",
    "2. **数据分块处理**：\n",
    "   - 对大数据集按时间或行分块处理，减少内存占用。\n",
    "3. **优化绘图性能**：\n",
    "   - 仅在需要时生成图像，避免不必要的重复计算和绘制。\n",
    "\n",
    "---\n",
    "\n",
    "### **异常处理改进**\n",
    "1. **文件异常**：\n",
    "   - 捕获文件读取异常（如文件不存在、格式不正确），并输出清晰的错误提示。\n",
    "2. **参数异常**：\n",
    "   - 检查用户输入参数是否合理（如 `width_threshold` 和 `num_density` 是否超出范围）。\n",
    "3. **拟合异常**：\n",
    "   - 对指数拟合失败的列标记为警告，而不是终止整个脚本。\n",
    "4. **日志记录**：\n",
    "   - 使用 `logging` 模块记录异常信息和运行状态，方便调试。\n",
    "\n",
    "---\n",
    "\n",
    "### **模块化设计**\n",
    "1. **功能拆分**：\n",
    "   - 将指数拟合、峰值检测和绘图功能提取为独立模块或类。\n",
    "   - 示例：创建 `FittingModule` 和 `PeakDetectionModule` 两个独立模块。\n",
    "2. **增加复用性**：\n",
    "   - 将通用功能（如数据清洗、异常处理）设计为工具函数，支持其他项目复用。\n",
    "3. **测试覆盖**：\n",
    "   - 针对模块化后的代码，编写单元测试以覆盖所有主要功能。\n",
    "\n",
    "---\n",
    "\n",
    "### **用户体验改进**\n",
    "1. **增强可视化**：\n",
    "   - 添加更多图表交互性（如 `plotly` 支持放大和查看详细数据点）。\n",
    "   - 在分析图中添加标注和颜色区分，提高可读性。\n",
    "2. **动态运行反馈**：\n",
    "   - 在处理大数据时，显示每个列的处理进度（如使用 `tqdm` 模块）。\n",
    "3. **错误修复提示**：\n",
    "   - 如果出现错误，提供修复建议，而不仅仅是报错信息。\n",
    "\n",
    "---\n",
    "\n",
    "### **数据格式扩展**\n",
    "1. **支持更多数据格式**：\n",
    "   - 增加对 CSV、Excel 和 HDF5 等数据格式的支持。\n",
    "2. **灵活数据输入**：\n",
    "   - 让用户指定数据格式和列名，而不是强制依赖固定命名规则。\n",
    "\n",
    "---\n",
    "\n",
    "### **代码维护与扩展**\n",
    "1. **添加注释和文档**：\n",
    "   - 为每个函数添加详细注释，包括参数解释和返回值说明。\n",
    "   - 提供完整的用户文档，指导如何使用脚本及调整参数。\n",
    "2. **代码版本控制**：\n",
    "   - 使用 `git` 或其他版本控制工具，管理代码的修改历史。\n",
    "3. **持续集成**：\n",
    "   - 引入自动化测试（如 `GitHub Actions`），确保代码修改不会引入新问题。\n",
    "\n",
    "---\n",
    "\n",
    "### **总结**\n",
    "通过以上优化措施，代码的可移植性、性能、可读性和用户体验将大大提升，同时为未来的功能扩展奠定基础。如果有任何具体问题，欢迎进一步讨论！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.optimize import curve_fit\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- 配置模块 -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- 配置模块 -------------------------- #\n",
    "def load_config(config_file):\n",
    "    \"\"\"\n",
    "    加载配置文件（支持 JSON 和 YAML）。\n",
    "    \n",
    "    参数:\n",
    "    - config_file (str): 配置文件的路径。\n",
    "    \n",
    "    返回:\n",
    "    - dict: 包含配置参数的字典。\n",
    "    \"\"\"\n",
    "    _, ext = os.path.splitext(config_file)\n",
    "    try:\n",
    "        with open(config_file, 'r') as file:\n",
    "            if ext == '.json':\n",
    "                return json.load(file)\n",
    "            elif ext in ('.yaml', '.yml'):\n",
    "                return yaml.safe_load(file)\n",
    "            else:\n",
    "                raise ValueError(\"不支持的配置文件格式，请使用 JSON 或 YAML。\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"配置文件 {config_file} 不存在，请检查路径。\")\n",
    "    except (json.JSONDecodeError, yaml.YAMLError):\n",
    "        raise ValueError(f\"配置文件 {config_file} 格式错误，无法解析。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N0': 2600.0, 'Nsc': 3900.0, 'input_dir': 'C:\\\\Users\\\\husky\\\\Desktop\\\\peek-find\\\\PEM4Fe\\\\data\\\\cool700\\\\nc2600', 'output_dir': 'C:\\\\Users\\\\husky\\\\Desktop\\\\peek-find\\\\PEM4Fe\\\\data\\\\output', 'initial_fit_points': 10, 'max_iterations': 100, 'min_r_squared': 0.95, 'num_density': 6, 'pressure': 360.0, 'width_threshold': 5}\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "# config = load_config(\"/home/jhzhai/Nucleation/peek-find/config.yaml\")  # 或者 \"config.json\"\n",
    "config = load_config(\"C:\\\\Users\\\\husky\\\\Desktop\\\\peek-find\\\\PEM4Fe\\\\data\\\\config.yaml\")  # 或者 \"config.json\"\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments(args=None):\n",
    "    \"\"\"\n",
    "    解析命令行参数，支持 Jupyter Notebook。\n",
    "    \n",
    "    参数:\n",
    "    - args (list): 自定义参数列表（默认为 None，使用 sys.argv）。\n",
    "    \n",
    "    返回:\n",
    "    - argparse.Namespace: 包含解析后的参数对象。\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"解析脚本运行参数\")\n",
    "    \n",
    "    # 添加参数\n",
    "    parser.add_argument(\"--config\", type=str, default=\"config.json\", help=\"配置文件的路径（默认为 config.json）\")\n",
    "    parser.add_argument(\"--input_dir\", type=str, help=\"输入数据文件的目录，覆盖配置文件中的 input_dir 参数\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, help=\"输出结果保存的目录，覆盖配置文件中的 output_dir 参数\")\n",
    "    parser.add_argument(\"--Nsc\", type=float, help=\"Nsc 参数，覆盖配置文件中的 Nsc 值\")\n",
    "    parser.add_argument(\"--N0\", type=float, help=\"N0 参数，覆盖配置文件中的 N0 值\")\n",
    "    parser.add_argument(\"--pressure\", type=float, help=\"pressure 参数，覆盖配置文件中的 pressure 值\")\n",
    "    \n",
    "    # 如果在 Jupyter Notebook 中运行，传入自定义参数\n",
    "    if args is None:\n",
    "        args = sys.argv[1:]  # 默认从命令行读取参数\n",
    "\n",
    "    # 覆写配置文件并保存yaml文件\n",
    "    args = parser.parse_args(args)\n",
    "    if args.input_dir:\n",
    "        config[\"input_dir\"] = args.input_dir\n",
    "    if args.output_dir:\n",
    "        config[\"output_dir\"] = args.output_dir\n",
    "    if args.Nsc:\n",
    "        config[\"Nsc\"] = args.Nsc\n",
    "    if args.N0:\n",
    "        config[\"N0\"] = args.N0\n",
    "    if args.pressure:\n",
    "        config[\"pressure\"] = args.pressure\n",
    "    with open(r\"C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\config.yaml\", \"w\") as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='config.json', input_dir='C:\\\\Users\\\\husky\\\\Desktop\\\\peek-find\\\\PEM4Fe\\\\data\\\\cool700\\\\nc2600', output_dir='C:\\\\Users\\\\husky\\\\Desktop\\\\peek-find\\\\PEM4Fe\\\\data\\\\output', Nsc=3900.0, N0=2600.0, pressure=360.0)\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "if __name__ == \"__main__\":\n",
    "    # 自定义参数列表（模拟命令行）\n",
    "    # notebook_args = [\n",
    "    #     \"--config\", \"config.json\",\n",
    "    #     \"--input_dir\", \"/home/jhzhai/Nucleation/peek-find/cool700/nc2600\",\n",
    "    #     \"--output_dir\", \"/home/jhzhai/Nucleation/peek-find/cool700/nc2600\",\n",
    "    #     \"--Nsc\", \"100.0\",\n",
    "    #     \"--N0\", \"50.0\"\n",
    "    # ]\n",
    "    notebook_args = [\n",
    "        \"--config\", \"config.json\",\n",
    "        \"--input_dir\", r\"C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\",\n",
    "        \"--output_dir\", r\"C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\",\n",
    "        \"--pressure\",\"360\",\n",
    "        \"--Nsc\", \"3900.0\",\n",
    "        \"--N0\", \"2600.0\"\n",
    "\n",
    "    ]\n",
    "    args = parse_arguments(notebook_args)\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=args.input_dir\n",
    "output_dir=args.output_dir\n",
    "Press=args.pressure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(output_dir=\"./logs\", log_file=\"app.log\", level=logging.INFO):\n",
    "    \"\"\"\n",
    "    设置日志记录。\n",
    "    \n",
    "    参数:\n",
    "    - output_dir (str): 日志文件保存的目录，默认是 \"./logs\"。\n",
    "    - log_file (str): 日志文件名，默认保存为 \"app.log\"。\n",
    "    - level (int): 日志级别，默认是 INFO。\n",
    "    \n",
    "    返回:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # 确保日志目录存在\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 完整日志文件路径\n",
    "    log_file_path = os.path.join(output_dir, log_file)\n",
    "\n",
    "    # 清理旧的日志配置\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "    # 配置日志格式\n",
    "    log_format = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "\n",
    "    # 配置日志记录\n",
    "    logging.basicConfig(\n",
    "        level=level,  # 设置日志级别\n",
    "        format=log_format,  # 设置日志格式\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file_path),  # 将日志写入文件\n",
    "            logging.StreamHandler()             # 同时输出到控制台\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 测试日志\n",
    "    logging.info(f\"日志文件保存路径: {log_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:08:05,124 - root - INFO - 日志文件保存路径: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\application.log\n",
      "2024-12-13 21:08:05,125 - root - DEBUG - DEBUG log test\n",
      "2024-12-13 21:08:05,125 - root - INFO - INFO log test\n",
      "2024-12-13 21:08:05,127 - root - WARNING - WARNING log test\n",
      "2024-12-13 21:08:05,127 - root - ERROR - ERROR log test\n",
      "2024-12-13 21:08:05,128 - root - CRITICAL - CRITICAL log test\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置日志保存目录和文件名\n",
    "    log_file = \"application.log\"\n",
    "    \n",
    "    # 调用日志设置函数\n",
    "    setup_logging(output_dir=output_dir, log_file=log_file, level=logging.DEBUG)\n",
    "\n",
    "    # 测试日志输出\n",
    "    logging.debug(\"DEBUG log test\")\n",
    "    logging.info(\"INFO log test\")\n",
    "    logging.warning(\"WARNING log test\")\n",
    "    logging.error(\"ERROR log test\")\n",
    "    logging.critical(\"CRITICAL log test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- 数据处理模块 -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_from_files(directory):\n",
    "    \"\"\"\n",
    "    从指定目录中收集所有符合命名规则的文本文件，并合并为一个 DataFrame。\n",
    "    \n",
    "    参数:\n",
    "    - directory (str): 数据文件所在目录路径。\n",
    "    \n",
    "    返回:\n",
    "    - pd.DataFrame: 合并后的数据框，包含时间列 't' 和多个 'N_' 列。\n",
    "    \"\"\"\n",
    "    logging.info(f\"开始从目录 {directory} 中收集数据文件...\")\n",
    "    combined_df = pd.DataFrame()\n",
    "    file_count = 0\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        logging.error(f\"指定的目录 {directory} 不存在。\")\n",
    "        return combined_df\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith('pem-Nc-') and filename.endswith('.txt'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                suffix = filename.split('-')[-1].split('.')[0]\n",
    "                # 使用原始字符串避免转义警告\n",
    "                df = pd.read_csv(filepath, sep=r'\\s+', names=['t', f'N_{suffix}'])\n",
    "                if combined_df.empty:\n",
    "                    combined_df = df\n",
    "                else:\n",
    "                    combined_df = pd.merge(combined_df, df, on='t', how='outer')\n",
    "                file_count += 1\n",
    "                logging.info(f\"成功读取文件: {filepath}\")\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"读取文件 {filepath} 失败: {e}\")\n",
    "\n",
    "    if file_count == 0:\n",
    "        logging.warning(f\"目录 {directory} 中没有找到符合命名规则的文件。\")\n",
    "    else:\n",
    "        logging.info(f\"共处理了 {file_count} 个文件。\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def clean_data(t, N):\n",
    "    \"\"\"\n",
    "    清洗数据，去除无效值（NaN 和无穷值）。\n",
    "    \n",
    "    参数:\n",
    "    - t (pd.Series): 时间序列。\n",
    "    - N (pd.Series): 数据序列。\n",
    "    \n",
    "    返回:\n",
    "    - pd.Series: 清洗后的时间序列。\n",
    "    - pd.Series: 清洗后的数据序列。\n",
    "    \"\"\"\n",
    "    logging.info(\"开始清洗数据...\")\n",
    "    initial_length = len(N)\n",
    "\n",
    "    # 去除无效值\n",
    "    clean_mask = np.isfinite(N)\n",
    "    t_clean = t[clean_mask]\n",
    "    N_clean = N[clean_mask]\n",
    "\n",
    "    # 重置索引\n",
    "    t_clean = t_clean.reset_index(drop=True)\n",
    "    N_clean = N_clean.reset_index(drop=True)\n",
    "\n",
    "    cleaned_length = len(N_clean)\n",
    "    logging.info(f\"数据清洗完成：原始数据点 {initial_length} 个，清洗后数据点 {cleaned_length} 个。\")\n",
    "    \n",
    "    return t_clean, N_clean\n",
    "\n",
    "def load_clean_save_data(directory_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    加载、清洗并保存数据。\n",
    "    \n",
    "    参数:\n",
    "    - directory_path (str): 数据文件所在目录路径。\n",
    "    - output_csv_path (str): 保存合并后数据的 CSV 文件名。\n",
    "    \n",
    "    返回:\n",
    "    - pd.DataFrame: 清洗后的数据框。\n",
    "    - float: 从目录名中提取的 nc 值。\n",
    "    \"\"\"\n",
    "    # 提取目录名中的 nc 值\n",
    "    base_dir = os.path.basename(directory_path)\n",
    "    try:\n",
    "        nc_str = [part for part in base_dir.split('/') if 'nc' in part][0]\n",
    "        nc = float(nc_str.replace('nc', ''))\n",
    "    except (IndexError, ValueError):\n",
    "        logging.error(\"无法从目录名中提取 'nc' 值，请确保目录名包含 'nc' 后跟数值，例如 'nc1000'\")\n",
    "        nc = None\n",
    "    \n",
    "    collected_data = collect_data_from_files(directory_path)\n",
    "\n",
    "    output_csv_path=output_csv_path+'\\pem_N.csv'\n",
    "    save_to_csv(collected_data, os.path.join(directory_path, output_csv_path))\n",
    "    logging.info(f\"nc={nc}已处理完毕\")\n",
    "    df = pd.read_csv(os.path.join(directory_path, output_csv_path))\n",
    "    return df, nc\n",
    "\n",
    "def save_to_csv(dataframe, output_file):\n",
    "    \"\"\"\n",
    "    将 DataFrame 保存为 CSV 文件。\n",
    "    \n",
    "    参数:\n",
    "    - dataframe (pd.DataFrame): 要保存的数据框。\n",
    "    - output_file (str): 输出 CSV 文件路径。\n",
    "    \"\"\"\n",
    "    dataframe.to_csv(output_file, index=False)\n",
    "    logging.info(f\"数据成功保存到 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:08:05,965 - root - INFO - 开始从目录 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600 中收集数据文件...\n",
      "2024-12-13 21:08:05,968 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-12345.txt\n",
      "2024-12-13 21:08:05,972 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-147.txt\n",
      "2024-12-13 21:08:05,978 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-15173.txt\n",
      "2024-12-13 21:08:05,982 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-1660.txt\n",
      "2024-12-13 21:08:05,990 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-19081.txt\n",
      "2024-12-13 21:08:05,994 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-20781.txt\n",
      "2024-12-13 21:08:05,998 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-22608.txt\n",
      "2024-12-13 21:08:06,003 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-23261.txt\n",
      "2024-12-13 21:08:06,009 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-24197.txt\n",
      "2024-12-13 21:08:06,013 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-25159.txt\n",
      "2024-12-13 21:08:06,017 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-25652.txt\n",
      "2024-12-13 21:08:06,022 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-26694.txt\n",
      "2024-12-13 21:08:06,026 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-26700.txt\n",
      "2024-12-13 21:08:06,030 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-28657.txt\n",
      "2024-12-13 21:08:06,035 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-32741.txt\n",
      "2024-12-13 21:08:06,040 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-7213.txt\n",
      "2024-12-13 21:08:06,044 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-740.txt\n",
      "2024-12-13 21:08:06,051 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-9146.txt\n",
      "2024-12-13 21:08:06,057 - root - INFO - 成功读取文件: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\cool700\\nc2600\\pem-Nc-3900.00-969.txt\n",
      "2024-12-13 21:08:06,058 - root - INFO - 共处理了 19 个文件。\n",
      "2024-12-13 21:08:06,074 - root - INFO - 数据成功保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\pem_N.csv\n",
      "2024-12-13 21:08:06,075 - root - INFO - nc=2600.0已处理完毕\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    collected_data,nc = load_clean_save_data(input_dir,output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- 拟合模块 -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- 拟合模块 -------------------------- #\n",
    "# src/fitting.py\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import logging\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FittingModule:\n",
    "    \"\"\"指数拟合模块\"\"\"\n",
    "    \n",
    "    def __init__(self, logger=None, config=None):\n",
    "        \"\"\"\n",
    "        初始化拟合模块。\n",
    "        \n",
    "        参数:\n",
    "        - logger (logging.Logger): 可选的日志记录器。如果未提供，将使用根日志记录器。\n",
    "        - config (dict): 配置字典，包含拟合参数。\n",
    "        \"\"\"\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        self.config = config or {}\n",
    "        self.initial_fit_points = self.config.get('initial_fit_points', 10)\n",
    "        self.min_r_squared = self.config.get('min_r_squared', 0.95)\n",
    "        self.max_iterations = self.config.get('max_iterations', 10)\n",
    "        self.output_dir = self.config.get('output_dir', './output')\n",
    "        \n",
    "        logging.info(\"拟合模块初始化完成, output_dir: %s\", self.output_dir)\n",
    "        \n",
    "        # 创建输出目录的子文件夹\n",
    "        self.fit_output_dir = os.path.join(self.output_dir, \"1_exponential_fit\")\n",
    "        os.makedirs(self.fit_output_dir, exist_ok=True)\n",
    "    \n",
    "    def exponential_func(self, t, a, b, c):\n",
    "        \"\"\"\n",
    "        定义拟合函数：a * exp(b * (t - c)) + d * t + e\n",
    "        \n",
    "        参数:\n",
    "        - t (array-like): 自变量数据。\n",
    "        - a, b, c, d, e (float): 拟合参数。\n",
    "        \n",
    "        返回:\n",
    "        - array-like: 函数值。\n",
    "        \"\"\"\n",
    "        return a + b*(t-c)**(3/2)\n",
    "        # return a * np.exp(b * (t - c)) + d\n",
    "    \n",
    "    def fit_dynamic(self, t, N, index, initial_fit_points=None, min_r_squared=None, max_iterations=None):\n",
    "        \"\"\"\n",
    "        动态进行指数拟合，逐步扩大拟合范围直到满足置信度要求或达到最大迭代次数。\n",
    "        \n",
    "        参数:\n",
    "        - t (pd.Series or np.ndarray): 时间序列。\n",
    "        - N (pd.Series or np.ndarray): 数据序列。\n",
    "        - initial_fit_points (int, optional): 初始拟合的数据点数。\n",
    "        - min_r_squared (float, optional): 最小的 R² 值要求。\n",
    "        - max_iterations (int, optional): 最大拟合尝试次数，防止无限循环。\n",
    "        \n",
    "        返回:\n",
    "        - dict or None: 包含拟合参数和 R² 值的字典，若拟合失败则返回 None。\n",
    "        \"\"\"\n",
    "        # 使用传入的参数或配置中的参数\n",
    "        initial_fit_points = initial_fit_points or self.initial_fit_points\n",
    "        min_r_squared = min_r_squared or self.min_r_squared\n",
    "        max_iterations = max_iterations or self.max_iterations\n",
    "        \n",
    "        self.logger.info(\"开始动态指数拟合...\\n - 初始拟合点数: %d  - 最小 R²: %.2f  - 最大迭代次数: %d\", initial_fit_points, min_r_squared, max_iterations)\n",
    "        \n",
    "        # 确保输入为 numpy 数组\n",
    "        t = np.array(t)\n",
    "        N = np.array(N)\n",
    "        \n",
    "        total_points = len(t)\n",
    "        if total_points < initial_fit_points:\n",
    "            self.logger.error(f\"数据点不足，无法进行拟合。需要至少 {initial_fit_points} 个点，当前有 {total_points} 个点。\")\n",
    "            return None\n",
    "        \n",
    "        # 初始拟合范围：最后 initial_fit_points 个点\n",
    "        start_idx = total_points - initial_fit_points\n",
    "        end_idx = total_points\n",
    "        iteration = 0\n",
    "        new_popt = None\n",
    "        new_r_squared = -np.inf\n",
    "        \n",
    "        while iteration < max_iterations and start_idx >= 0:\n",
    "            self.logger.debug(f\"拟合迭代 {iteration + 1}: 使用数据点 {start_idx} 到 {end_idx}（共 {end_idx - start_idx} 个点）\")\n",
    "            t_fit = t[start_idx:end_idx]\n",
    "            N_fit = N[start_idx:end_idx]\n",
    "            \n",
    "            try:\n",
    "                # # 初始参数猜测\n",
    "                # initial_params = [1.0, 0.1, t_fit[0], np.min(N_fit)]\n",
    "                # # 参数边界\n",
    "                # bounds = ([0, 0, t_fit[0], 0], [np.inf, np.inf, t_fit[-1], np.inf])\n",
    "\n",
    "                # 初始参数猜测\n",
    "                initial_params = [np.min(N_fit), 1, np.min(t_fit)]\n",
    "                # 参数边界\n",
    "                bounds = ([0, 0, 0], [np.max(N_fit), np.inf, np.min(t_fit)])\n",
    "                \n",
    "                popt, pcov = curve_fit(\n",
    "                    self.exponential_func, \n",
    "                    t_fit, \n",
    "                    N_fit, \n",
    "                    p0=initial_params, \n",
    "                    bounds=bounds, \n",
    "                    maxfev=10000\n",
    "                )\n",
    "                \n",
    "                # 计算拟合结果\n",
    "                residuals = N_fit - self.exponential_func(t_fit, *popt)\n",
    "                ss_res = np.sum(residuals**2)\n",
    "                ss_tot = np.sum((N_fit - np.mean(N_fit))**2)\n",
    "                r_squared = 1 - (ss_res / ss_tot)\n",
    "                \n",
    "                self.logger.debug(f\"拟合结果：参数={popt}, R²={r_squared:.4f}\")\n",
    "                \n",
    "                # 检查 R² 是否达到要求\n",
    "                if r_squared < min_r_squared:\n",
    "                    self.logger.info(f\"拟合成功，R²={r_squared:.4f}，使用数据点 {start_idx} 到 {end_idx}\")\n",
    "                    # 绘制并保存拟合结果\n",
    "                    self.plot_fit(t_fit, N_fit, new_t_fit, index, new_popt, new_r_squared, new_start_idx, new_end_idx)\n",
    "                    return {\n",
    "                        \"index\": index,\n",
    "                        'params': new_popt,\n",
    "                        'r_squared': new_r_squared,\n",
    "                        'start_idx': new_start_idx,\n",
    "                        'end_idx': new_end_idx\n",
    "                    }\n",
    "                else:\n",
    "                    # 保存最佳拟合结果\n",
    "                    new_popt = popt\n",
    "                    new_r_squared = r_squared\n",
    "                    new_start_idx = start_idx\n",
    "                    new_end_idx = end_idx\n",
    "                    new_t_fit = t_fit\n",
    "                \n",
    "                # 扩大拟合范围\n",
    "                start_idx = max(0, start_idx - initial_fit_points)\n",
    "                iteration += 1\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                self.logger.warning(f\"拟合失败在数据点 {start_idx} 到 {end_idx}: {e}\")\n",
    "                # 扩大拟合范围继续尝试\n",
    "                start_idx = max(0, start_idx - initial_fit_points)\n",
    "                iteration += 1\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"拟合过程中发生未预料的错误: {e}\")\n",
    "                return None\n",
    "        \n",
    "        # 如果未达到要求，返回最佳结果并绘图\n",
    "        if new_r_squared >= min_r_squared:\n",
    "            self.logger.warning(f\"未达到最小 R²={min_r_squared}，最佳拟合值 R²={new_r_squared:.4f}\")\n",
    "            return None\n",
    "        elif iteration >= max_iterations:\n",
    "            self.logger.error(\"超过限制次数，所有拟合尝试均失败。\")\n",
    "            return None\n",
    "    \n",
    "    def plot_fit(self, t_fit, N_fit, new_t_fit, index, popt, r_squared, start_idx, end_idx):\n",
    "        \"\"\"\n",
    "        绘制拟合曲线并保存图像。\n",
    "        \n",
    "        参数:\n",
    "        - t_fit (np.ndarray): 拟合的时间序列。\n",
    "        - N_fit (np.ndarray): 拟合的数据序列。\n",
    "        - popt (list): 拟合参数。\n",
    "        - r_squared (float): 拟合的 R² 值。\n",
    "        - start_idx (int): 拟合的起始索引。\n",
    "        - end_idx (int): 拟合的结束索引。\n",
    "        \n",
    "        返回:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(t_fit, N_fit, label='Data', color='blue')\n",
    "        fitted_N = self.exponential_func(new_t_fit, *popt)\n",
    "        plt.plot(new_t_fit, fitted_N, label=f'Fit (R²={r_squared:.4f})', color='red')\n",
    "        plt.title(f'N{index} Exponential Fit: Data points {start_idx} to {end_idx}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('N')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # 定义保存路径\n",
    "        plot_filename = f\"1_exponential_fit\\{index}-{start_idx}_{end_idx}.png\"\n",
    "        print(plot_filename)\n",
    "        plot_path = os.path.join(self.output_dir, plot_filename)\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        self.logger.info(f\"拟合图已保存到 {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 00:06:34,694 - root - INFO - 拟合模块初始化完成, output_dir: C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\n",
      "2024-12-14 00:06:34,695 - root - INFO - FittingModule 实例已初始化。\n",
      "2024-12-14 00:06:34,696 - root - INFO - 开始执行动态指数拟合：N_12345...\n",
      "2024-12-14 00:06:34,697 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:34,697 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 396 个。\n",
      "2024-12-14 00:06:34,698 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:34,699 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 386 到 396（共 10 个点）\n",
      "2024-12-14 00:06:34,712 - __main__ - DEBUG - 拟合结果：参数=[4.08580001e+03 1.12585932e-12 2.96837174e+02], R²=-0.0000\n",
      "2024-12-14 00:06:34,713 - __main__ - INFO - 拟合成功，R²=-0.0000，使用数据点 386 到 396\n",
      "2024-12-14 00:06:34,714 - __main__ - ERROR - 拟合过程中发生未预料的错误: local variable 'new_t_fit' referenced before assignment\n",
      "2024-12-14 00:06:34,715 - root - ERROR - 拟合失败。\n",
      "2024-12-14 00:06:34,716 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:34,717 - root - INFO - 开始执行动态指数拟合：N_147...\n",
      "2024-12-14 00:06:34,718 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:34,720 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 76 个。\n",
      "2024-12-14 00:06:34,722 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:34,723 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 66 到 76（共 10 个点）\n",
      "2024-12-14 00:06:34,736 - __main__ - DEBUG - 拟合结果：参数=[10234.30452999   301.00854965    65.36635371], R²=0.9967\n",
      "2024-12-14 00:06:34,739 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 56 到 76（共 20 个点）\n",
      "2024-12-14 00:06:34,748 - __main__ - DEBUG - 拟合结果：参数=[7393.37319304  142.59175636   57.        ], R²=0.9591\n",
      "2024-12-14 00:06:34,749 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 46 到 76（共 30 个点）\n",
      "2024-12-14 00:06:34,758 - __main__ - DEBUG - 拟合结果：参数=[5693.74905525   76.64517558   47.        ], R²=0.9091\n",
      "2024-12-14 00:06:34,759 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 36 到 76（共 40 个点）\n",
      "2024-12-14 00:06:34,765 - __main__ - DEBUG - 拟合结果：参数=[4705.78654646   48.17594322   37.        ], R²=0.8701\n",
      "2024-12-14 00:06:34,765 - __main__ - INFO - 拟合成功，R²=0.8701，使用数据点 36 到 76\n",
      "2024-12-14 00:06:34,893 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_147-46_76.png\n",
      "2024-12-14 00:06:34,894 - root - INFO - 拟合成功。R² = 0.9091\n",
      "2024-12-14 00:06:34,895 - root - INFO - 拟合参数: a = 5693.7491, b = 76.6452, c = 47.0000\n",
      "2024-12-14 00:06:34,896 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:34,897 - root - INFO - 开始执行动态指数拟合：N_15173...\n",
      "2024-12-14 00:06:34,897 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:34,899 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 543 个。\n",
      "2024-12-14 00:06:34,899 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:34,900 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 533 到 543（共 10 个点）\n",
      "2024-12-14 00:06:34,911 - __main__ - DEBUG - 拟合结果：参数=[9630.99154199  274.79589347  531.24871887], R²=0.9965\n",
      "2024-12-14 00:06:34,911 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 523 到 543（共 20 个点）\n",
      "2024-12-14 00:06:34,919 - __main__ - DEBUG - 拟合结果：参数=[6550.87485577  158.95267461  524.        ], R²=0.9845\n",
      "2024-12-14 00:06:34,920 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 513 到 543（共 30 个点）\n",
      "2024-12-14 00:06:34,928 - __main__ - DEBUG - 拟合结果：参数=[4865.15495204   83.67940778  514.        ], R²=0.9204\n",
      "2024-12-14 00:06:34,929 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 503 到 543（共 40 个点）\n",
      "2024-12-14 00:06:34,936 - __main__ - DEBUG - 拟合结果：参数=[4342.54703408   49.14932185  504.        ], R²=0.8344\n",
      "2024-12-14 00:06:34,937 - __main__ - INFO - 拟合成功，R²=0.8344，使用数据点 503 到 543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_exponential_fit\\N_147-46_76.png\n",
      "1_exponential_fit\\N_15173-513_543.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 00:06:35,061 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_15173-513_543.png\n",
      "2024-12-14 00:06:35,062 - root - INFO - 拟合成功。R² = 0.9204\n",
      "2024-12-14 00:06:35,062 - root - INFO - 拟合参数: a = 4865.1550, b = 83.6794, c = 514.0000\n",
      "2024-12-14 00:06:35,063 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:35,064 - root - INFO - 开始执行动态指数拟合：N_1660...\n",
      "2024-12-14 00:06:35,065 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:35,066 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 164 个。\n",
      "2024-12-14 00:06:35,067 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:35,068 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 154 到 164（共 10 个点）\n",
      "2024-12-14 00:06:35,081 - __main__ - DEBUG - 拟合结果：参数=[9675.99335256  405.7724111   154.97504969], R²=0.9983\n",
      "2024-12-14 00:06:35,082 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 144 到 164（共 20 个点）\n",
      "2024-12-14 00:06:35,090 - __main__ - DEBUG - 拟合结果：参数=[6519.56006003  142.91388554  145.        ], R²=0.9168\n",
      "2024-12-14 00:06:35,091 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 134 到 164（共 30 个点）\n",
      "2024-12-14 00:06:35,097 - __main__ - DEBUG - 拟合结果：参数=[4998.63260716   75.07267209  135.        ], R²=0.8686\n",
      "2024-12-14 00:06:35,097 - __main__ - INFO - 拟合成功，R²=0.8686，使用数据点 134 到 164\n",
      "2024-12-14 00:06:35,223 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_1660-144_164.png\n",
      "2024-12-14 00:06:35,225 - root - INFO - 拟合成功。R² = 0.9168\n",
      "2024-12-14 00:06:35,225 - root - INFO - 拟合参数: a = 6519.5601, b = 142.9139, c = 145.0000\n",
      "2024-12-14 00:06:35,226 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:35,227 - root - INFO - 开始执行动态指数拟合：N_19081...\n",
      "2024-12-14 00:06:35,228 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:35,229 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 796 个。\n",
      "2024-12-14 00:06:35,229 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:35,230 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 786 到 796（共 10 个点）\n",
      "2024-12-14 00:06:35,241 - __main__ - DEBUG - 拟合结果：参数=[11338.1111776    271.50131304   786.28877274], R²=0.9919\n",
      "2024-12-14 00:06:35,242 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 776 到 796（共 20 个点）\n",
      "2024-12-14 00:06:35,250 - __main__ - DEBUG - 拟合结果：参数=[7533.63704275  133.71525065  777.        ], R²=0.9802\n",
      "2024-12-14 00:06:35,251 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 766 到 796（共 30 个点）\n",
      "2024-12-14 00:06:35,259 - __main__ - DEBUG - 拟合结果：参数=[5339.00882968   77.63137085  767.        ], R²=0.9559\n",
      "2024-12-14 00:06:35,260 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 756 到 796（共 40 个点）\n",
      "2024-12-14 00:06:35,267 - __main__ - DEBUG - 拟合结果：参数=[4254.74661954   49.39996417  757.        ], R²=0.9153\n",
      "2024-12-14 00:06:35,267 - __main__ - DEBUG - 拟合迭代 5: 使用数据点 746 到 796（共 50 个点）\n",
      "2024-12-14 00:06:35,275 - __main__ - DEBUG - 拟合结果：参数=[3497.32083788   34.48510545  747.        ], R²=0.8833\n",
      "2024-12-14 00:06:35,276 - __main__ - INFO - 拟合成功，R²=0.8833，使用数据点 746 到 796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_exponential_fit\\N_1660-144_164.png\n",
      "1_exponential_fit\\N_19081-756_796.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 00:06:35,401 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_19081-756_796.png\n",
      "2024-12-14 00:06:35,402 - root - INFO - 拟合成功。R² = 0.9153\n",
      "2024-12-14 00:06:35,403 - root - INFO - 拟合参数: a = 4254.7466, b = 49.4000, c = 757.0000\n",
      "2024-12-14 00:06:35,404 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:35,404 - root - INFO - 开始执行动态指数拟合：N_20781...\n",
      "2024-12-14 00:06:35,405 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:35,406 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 374 个。\n",
      "2024-12-14 00:06:35,407 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:35,407 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 364 到 374（共 10 个点）\n",
      "2024-12-14 00:06:35,415 - __main__ - DEBUG - 拟合结果：参数=[6208.82016141  168.50562751  355.52444126], R²=0.9969\n",
      "2024-12-14 00:06:35,416 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 354 到 374（共 20 个点）\n",
      "2024-12-14 00:06:35,428 - __main__ - DEBUG - 拟合结果：参数=[7644.68030562  136.30424978  355.        ], R²=0.9853\n",
      "2024-12-14 00:06:35,429 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 344 到 374（共 30 个点）\n",
      "2024-12-14 00:06:35,442 - __main__ - DEBUG - 拟合结果：参数=[5610.99818454   77.27551196  345.        ], R²=0.9530\n",
      "2024-12-14 00:06:35,443 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 334 到 374（共 40 个点）\n",
      "2024-12-14 00:06:35,452 - __main__ - DEBUG - 拟合结果：参数=[4450.27208941   49.65620695  335.        ], R²=0.9173\n",
      "2024-12-14 00:06:35,453 - __main__ - DEBUG - 拟合迭代 5: 使用数据点 324 到 374（共 50 个点）\n",
      "2024-12-14 00:06:35,462 - __main__ - DEBUG - 拟合结果：参数=[3717.11588985   34.54315311  325.        ], R²=0.8832\n",
      "2024-12-14 00:06:35,463 - __main__ - INFO - 拟合成功，R²=0.8832，使用数据点 324 到 374\n",
      "2024-12-14 00:06:35,591 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_20781-334_374.png\n",
      "2024-12-14 00:06:35,592 - root - INFO - 拟合成功。R² = 0.9173\n",
      "2024-12-14 00:06:35,593 - root - INFO - 拟合参数: a = 4450.2721, b = 49.6562, c = 335.0000\n",
      "2024-12-14 00:06:35,594 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:35,594 - root - INFO - 开始执行动态指数拟合：N_22608...\n",
      "2024-12-14 00:06:35,595 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:35,596 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 197 个。\n",
      "2024-12-14 00:06:35,597 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:35,597 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 187 到 197（共 10 个点）\n",
      "2024-12-14 00:06:35,607 - __main__ - DEBUG - 拟合结果：参数=[10589.64758824   309.25407351   186.77224904], R²=0.9976\n",
      "2024-12-14 00:06:35,608 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 177 到 197（共 20 个点）\n",
      "2024-12-14 00:06:35,616 - __main__ - DEBUG - 拟合结果：参数=[7062.34513654  149.00053857  178.        ], R²=0.9733\n",
      "2024-12-14 00:06:35,617 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 167 到 197（共 30 个点）\n",
      "2024-12-14 00:06:35,623 - __main__ - DEBUG - 拟合结果：参数=[5329.58275643   79.74731959  168.        ], R²=0.9186\n",
      "2024-12-14 00:06:35,623 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 157 到 197（共 40 个点）\n",
      "2024-12-14 00:06:35,629 - __main__ - DEBUG - 拟合结果：参数=[4301.81301617   50.15222128  158.        ], R²=0.8776\n",
      "2024-12-14 00:06:35,630 - __main__ - INFO - 拟合成功，R²=0.8776，使用数据点 157 到 197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_exponential_fit\\N_20781-334_374.png\n",
      "1_exponential_fit\\N_22608-167_197.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 00:06:35,757 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_22608-167_197.png\n",
      "2024-12-14 00:06:35,758 - root - INFO - 拟合成功。R² = 0.9186\n",
      "2024-12-14 00:06:35,758 - root - INFO - 拟合参数: a = 5329.5828, b = 79.7473, c = 168.0000\n",
      "2024-12-14 00:06:35,759 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:35,760 - root - INFO - 开始执行动态指数拟合：N_23261...\n",
      "2024-12-14 00:06:35,760 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:35,761 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 390 个。\n",
      "2024-12-14 00:06:35,762 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:35,762 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 380 到 390（共 10 个点）\n",
      "2024-12-14 00:06:35,802 - __main__ - DEBUG - 拟合结果：参数=[9.01286559e-08 2.94393832e+00 2.44295039e+02], R²=0.9385\n",
      "2024-12-14 00:06:35,802 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 370 到 390（共 20 个点）\n",
      "2024-12-14 00:06:35,810 - __main__ - DEBUG - 拟合结果：参数=[4265.70073255   11.47827508  370.99999999], R²=0.7850\n",
      "2024-12-14 00:06:35,811 - __main__ - INFO - 拟合成功，R²=0.7850，使用数据点 370 到 390\n",
      "2024-12-14 00:06:35,942 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_23261-380_390.png\n",
      "2024-12-14 00:06:35,943 - root - INFO - 拟合成功。R² = 0.9385\n",
      "2024-12-14 00:06:35,943 - root - INFO - 拟合参数: a = 0.0000, b = 2.9439, c = 244.2950\n",
      "2024-12-14 00:06:35,944 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:35,945 - root - INFO - 开始执行动态指数拟合：N_24197...\n",
      "2024-12-14 00:06:35,946 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:35,946 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 403 个。\n",
      "2024-12-14 00:06:35,947 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:35,948 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 393 到 403（共 10 个点）\n",
      "2024-12-14 00:06:35,961 - __main__ - DEBUG - 拟合结果：参数=[4.25380001e+03 1.71779050e-12 3.57519295e+02], R²=-0.0000\n",
      "2024-12-14 00:06:35,962 - __main__ - INFO - 拟合成功，R²=-0.0000，使用数据点 393 到 403\n",
      "2024-12-14 00:06:35,962 - __main__ - ERROR - 拟合过程中发生未预料的错误: local variable 'new_t_fit' referenced before assignment\n",
      "2024-12-14 00:06:35,963 - root - ERROR - 拟合失败。\n",
      "2024-12-14 00:06:35,964 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:35,964 - root - INFO - 开始执行动态指数拟合：N_25159...\n",
      "2024-12-14 00:06:35,965 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:35,966 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 122 个。\n",
      "2024-12-14 00:06:35,967 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:35,969 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 112 到 122（共 10 个点）\n",
      "2024-12-14 00:06:35,977 - __main__ - DEBUG - 拟合结果：参数=[11118.59622219   293.56867929   112.2977716 ], R²=0.9981\n",
      "2024-12-14 00:06:35,977 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 102 到 122（共 20 个点）\n",
      "2024-12-14 00:06:35,985 - __main__ - DEBUG - 拟合结果：参数=[7421.25220722  138.25040952  103.        ], R²=0.9799\n",
      "2024-12-14 00:06:35,986 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 92 到 122（共 30 个点）\n",
      "2024-12-14 00:06:35,992 - __main__ - DEBUG - 拟合结果：参数=[5608.09986054   75.92861062   93.        ], R²=0.9342\n",
      "2024-12-14 00:06:35,993 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 82 到 122（共 40 个点）\n",
      "2024-12-14 00:06:36,000 - __main__ - DEBUG - 拟合结果：参数=[4933.27864716   45.8603623    83.        ], R²=0.8653\n",
      "2024-12-14 00:06:36,001 - __main__ - INFO - 拟合成功，R²=0.8653，使用数据点 82 到 122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_exponential_fit\\N_23261-380_390.png\n",
      "1_exponential_fit\\N_25159-92_122.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 00:06:36,134 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_25159-92_122.png\n",
      "2024-12-14 00:06:36,135 - root - INFO - 拟合成功。R² = 0.9342\n",
      "2024-12-14 00:06:36,135 - root - INFO - 拟合参数: a = 5608.0999, b = 75.9286, c = 93.0000\n",
      "2024-12-14 00:06:36,136 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:36,137 - root - INFO - 开始执行动态指数拟合：N_25652...\n",
      "2024-12-14 00:06:36,138 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:36,139 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 249 个。\n",
      "2024-12-14 00:06:36,140 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:36,140 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 239 到 249（共 10 个点）\n",
      "2024-12-14 00:06:36,151 - __main__ - DEBUG - 拟合结果：参数=[9366.96820557  236.88638715  236.84382142], R²=0.9936\n",
      "2024-12-14 00:06:36,152 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 229 到 249（共 20 个点）\n",
      "2024-12-14 00:06:36,163 - __main__ - DEBUG - 拟合结果：参数=[6479.617959    147.41202266  230.        ], R²=0.9885\n",
      "2024-12-14 00:06:36,164 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 219 到 249（共 30 个点）\n",
      "2024-12-14 00:06:36,176 - __main__ - DEBUG - 拟合结果：参数=[4547.01107465   81.07099721  220.        ], R²=0.9431\n",
      "2024-12-14 00:06:36,177 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 209 到 249（共 40 个点）\n",
      "2024-12-14 00:06:36,187 - __main__ - DEBUG - 拟合结果：参数=[3747.27133218   49.49073739  210.        ], R²=0.8802\n",
      "2024-12-14 00:06:36,188 - __main__ - INFO - 拟合成功，R²=0.8802，使用数据点 209 到 249\n",
      "2024-12-14 00:06:36,342 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_25652-219_249.png\n",
      "2024-12-14 00:06:36,343 - root - INFO - 拟合成功。R² = 0.9431\n",
      "2024-12-14 00:06:36,343 - root - INFO - 拟合参数: a = 4547.0111, b = 81.0710, c = 220.0000\n",
      "2024-12-14 00:06:36,344 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:36,345 - root - INFO - 开始执行动态指数拟合：N_26694...\n",
      "2024-12-14 00:06:36,346 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:36,346 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 59 个。\n",
      "2024-12-14 00:06:36,347 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:36,347 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 49 到 59（共 10 个点）\n",
      "2024-12-14 00:06:36,355 - __main__ - DEBUG - 拟合结果：参数=[10230.36900532   296.92005399    48.8166799 ], R²=0.9955\n",
      "2024-12-14 00:06:36,356 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 39 到 59（共 20 个点）\n",
      "2024-12-14 00:06:36,363 - __main__ - DEBUG - 拟合结果：参数=[6463.52694122  148.53932717   40.        ], R²=0.9798\n",
      "2024-12-14 00:06:36,364 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 29 到 59（共 30 个点）\n",
      "2024-12-14 00:06:36,369 - __main__ - DEBUG - 拟合结果：参数=[4478.67908907   81.97136107   30.        ], R²=0.9373\n",
      "2024-12-14 00:06:36,370 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 19 到 59（共 40 个点）\n",
      "2024-12-14 00:06:36,374 - __main__ - DEBUG - 拟合结果：参数=[3447.61637945   51.40231781   20.        ], R²=0.8911\n",
      "2024-12-14 00:06:36,375 - __main__ - INFO - 拟合成功，R²=0.8911，使用数据点 19 到 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_exponential_fit\\N_25652-219_249.png\n",
      "1_exponential_fit\\N_26694-29_59.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 00:06:36,506 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_26694-29_59.png\n",
      "2024-12-14 00:06:36,507 - root - INFO - 拟合成功。R² = 0.9373\n",
      "2024-12-14 00:06:36,508 - root - INFO - 拟合参数: a = 4478.6791, b = 81.9714, c = 30.0000\n",
      "2024-12-14 00:06:36,508 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:36,510 - root - INFO - 开始执行动态指数拟合：N_26700...\n",
      "2024-12-14 00:06:36,510 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:36,511 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 101 个。\n",
      "2024-12-14 00:06:36,512 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:36,513 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 91 到 101（共 10 个点）\n",
      "2024-12-14 00:06:36,522 - __main__ - DEBUG - 拟合结果：参数=[10386.47949412   248.40791293    89.47212031], R²=0.9974\n",
      "2024-12-14 00:06:36,523 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 81 到 101（共 20 个点）\n",
      "2024-12-14 00:06:36,530 - __main__ - DEBUG - 拟合结果：参数=[7845.07146307  135.3735586    82.        ], R²=0.9731\n",
      "2024-12-14 00:06:36,531 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 71 到 101（共 30 个点）\n",
      "2024-12-14 00:06:36,536 - __main__ - DEBUG - 拟合结果：参数=[5731.65110258   77.65979575   72.        ], R²=0.9470\n",
      "2024-12-14 00:06:36,537 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 61 到 101（共 40 个点）\n",
      "2024-12-14 00:06:36,542 - __main__ - DEBUG - 拟合结果：参数=[4383.76610194   51.02368626   62.        ], R²=0.9237\n",
      "2024-12-14 00:06:36,542 - __main__ - DEBUG - 拟合迭代 5: 使用数据点 51 到 101（共 50 个点）\n",
      "2024-12-14 00:06:36,546 - __main__ - DEBUG - 拟合结果：参数=[3387.13927487   36.60254729   52.        ], R²=0.9054\n",
      "2024-12-14 00:06:36,548 - __main__ - DEBUG - 拟合迭代 6: 使用数据点 41 到 101（共 60 个点）\n",
      "2024-12-14 00:06:36,552 - __main__ - DEBUG - 拟合结果：参数=[2734.75681429   27.34590032   42.        ], R²=0.8823\n",
      "2024-12-14 00:06:36,554 - __main__ - INFO - 拟合成功，R²=0.8823，使用数据点 41 到 101\n",
      "2024-12-14 00:06:36,676 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_26700-51_101.png\n",
      "2024-12-14 00:06:36,677 - root - INFO - 拟合成功。R² = 0.9054\n",
      "2024-12-14 00:06:36,678 - root - INFO - 拟合参数: a = 3387.1393, b = 36.6025, c = 52.0000\n",
      "2024-12-14 00:06:36,679 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:36,679 - root - INFO - 开始执行动态指数拟合：N_28657...\n",
      "2024-12-14 00:06:36,680 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:36,681 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 279 个。\n",
      "2024-12-14 00:06:36,682 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:36,682 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 269 到 279（共 10 个点）\n",
      "2024-12-14 00:06:36,688 - __main__ - DEBUG - 拟合结果：参数=[3.99590000e+03 4.32498014e-13 2.70000000e+02], R²=-0.0000\n",
      "2024-12-14 00:06:36,689 - __main__ - INFO - 拟合成功，R²=-0.0000，使用数据点 269 到 279\n",
      "2024-12-14 00:06:36,690 - __main__ - ERROR - 拟合过程中发生未预料的错误: local variable 'new_t_fit' referenced before assignment\n",
      "2024-12-14 00:06:36,690 - root - ERROR - 拟合失败。\n",
      "2024-12-14 00:06:36,691 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:36,692 - root - INFO - 开始执行动态指数拟合：N_32741...\n",
      "2024-12-14 00:06:36,692 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:36,694 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 964 个。\n",
      "2024-12-14 00:06:36,695 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:36,695 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 954 到 964（共 10 个点）\n",
      "2024-12-14 00:06:36,708 - __main__ - DEBUG - 拟合结果：参数=[8642.02833262  304.23431047  952.37370223], R²=0.9984\n",
      "2024-12-14 00:06:36,709 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 944 到 964（共 20 个点）\n",
      "2024-12-14 00:06:36,717 - __main__ - DEBUG - 拟合结果：参数=[5715.03083862  164.65291722  945.        ], R²=0.9703\n",
      "2024-12-14 00:06:36,718 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 934 到 964（共 30 个点）\n",
      "2024-12-14 00:06:36,728 - __main__ - DEBUG - 拟合结果：参数=[4085.94826756   85.50620621  935.        ], R²=0.9019\n",
      "2024-12-14 00:06:36,729 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 924 到 964（共 40 个点）\n",
      "2024-12-14 00:06:36,736 - __main__ - DEBUG - 拟合结果：参数=[3182.20724668   52.51128694  925.        ], R²=0.8506\n",
      "2024-12-14 00:06:36,737 - __main__ - INFO - 拟合成功，R²=0.8506，使用数据点 924 到 964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_exponential_fit\\N_26700-51_101.png\n",
      "1_exponential_fit\\N_32741-934_964.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 00:06:36,866 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_32741-934_964.png\n",
      "2024-12-14 00:06:36,867 - root - INFO - 拟合成功。R² = 0.9019\n",
      "2024-12-14 00:06:36,868 - root - INFO - 拟合参数: a = 4085.9483, b = 85.5062, c = 935.0000\n",
      "2024-12-14 00:06:36,868 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:36,870 - root - INFO - 开始执行动态指数拟合：N_7213...\n",
      "2024-12-14 00:06:36,870 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:36,871 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 669 个。\n",
      "2024-12-14 00:06:36,872 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:36,872 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 659 到 669（共 10 个点）\n",
      "2024-12-14 00:06:36,884 - __main__ - DEBUG - 拟合结果：参数=[10067.74297394   389.70594506   659.93291779], R²=0.9957\n",
      "2024-12-14 00:06:36,885 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 649 到 669（共 20 个点）\n",
      "2024-12-14 00:06:36,895 - __main__ - DEBUG - 拟合结果：参数=[6382.64509093  148.87095109  650.        ], R²=0.9423\n",
      "2024-12-14 00:06:36,897 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 639 到 669（共 30 个点）\n",
      "2024-12-14 00:06:36,907 - __main__ - DEBUG - 拟合结果：参数=[5003.28103504   76.35688338  640.        ], R²=0.8749\n",
      "2024-12-14 00:06:36,908 - __main__ - INFO - 拟合成功，R²=0.8749，使用数据点 639 到 669\n",
      "2024-12-14 00:06:37,044 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_7213-649_669.png\n",
      "2024-12-14 00:06:37,045 - root - INFO - 拟合成功。R² = 0.9423\n",
      "2024-12-14 00:06:37,045 - root - INFO - 拟合参数: a = 6382.6451, b = 148.8710, c = 650.0000\n",
      "2024-12-14 00:06:37,046 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:37,047 - root - INFO - 开始执行动态指数拟合：N_740...\n",
      "2024-12-14 00:06:37,047 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:37,048 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 238 个。\n",
      "2024-12-14 00:06:37,049 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:37,050 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 228 到 238（共 10 个点）\n",
      "2024-12-14 00:06:37,058 - __main__ - DEBUG - 拟合结果：参数=[10446.26941172   337.27154529   228.65020057], R²=0.9958\n",
      "2024-12-14 00:06:37,058 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 218 到 238（共 20 个点）\n",
      "2024-12-14 00:06:37,068 - __main__ - DEBUG - 拟合结果：参数=[6013.16316095  154.61998807  219.        ], R²=0.9785\n",
      "2024-12-14 00:06:37,069 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 208 到 238（共 30 个点）\n",
      "2024-12-14 00:06:37,075 - __main__ - DEBUG - 拟合结果：参数=[4209.1799628    82.92516301  209.        ], R²=0.9250\n",
      "2024-12-14 00:06:37,076 - __main__ - DEBUG - 拟合迭代 4: 使用数据点 198 到 238（共 40 个点）\n",
      "2024-12-14 00:06:37,080 - __main__ - DEBUG - 拟合结果：参数=[3382.90840317   50.63110689  199.        ], R²=0.8651\n",
      "2024-12-14 00:06:37,081 - __main__ - INFO - 拟合成功，R²=0.8651，使用数据点 198 到 238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_exponential_fit\\N_7213-649_669.png\n",
      "1_exponential_fit\\N_740-208_238.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 00:06:37,209 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_740-208_238.png\n",
      "2024-12-14 00:06:37,210 - root - INFO - 拟合成功。R² = 0.9250\n",
      "2024-12-14 00:06:37,210 - root - INFO - 拟合参数: a = 4209.1800, b = 82.9252, c = 209.0000\n",
      "2024-12-14 00:06:37,211 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:37,212 - root - INFO - 开始执行动态指数拟合：N_9146...\n",
      "2024-12-14 00:06:37,213 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:37,214 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 1724 个。\n",
      "2024-12-14 00:06:37,215 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:37,215 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 1714 到 1724（共 10 个点）\n",
      "2024-12-14 00:06:37,231 - __main__ - DEBUG - 拟合结果：参数=[9191.77750044  314.13173568 1712.95700777], R²=0.9990\n",
      "2024-12-14 00:06:37,232 - __main__ - DEBUG - 拟合迭代 2: 使用数据点 1704 到 1724（共 20 个点）\n",
      "2024-12-14 00:06:37,241 - __main__ - DEBUG - 拟合结果：参数=[7038.3745376   143.84887736 1705.        ], R²=0.9410\n",
      "2024-12-14 00:06:37,242 - __main__ - DEBUG - 拟合迭代 3: 使用数据点 1694 到 1724（共 30 个点）\n",
      "2024-12-14 00:06:37,250 - __main__ - DEBUG - 拟合结果：参数=[5352.16454827   77.05227204 1695.        ], R²=0.8953\n",
      "2024-12-14 00:06:37,251 - __main__ - INFO - 拟合成功，R²=0.8953，使用数据点 1694 到 1724\n",
      "2024-12-14 00:06:37,375 - __main__ - INFO - 拟合图已保存到 C:\\Users\\husky\\Desktop\\peek-find\\PEM4Fe\\data\\output\\1_exponential_fit\\N_9146-1704_1724.png\n",
      "2024-12-14 00:06:37,376 - root - INFO - 拟合成功。R² = 0.9410\n",
      "2024-12-14 00:06:37,377 - root - INFO - 拟合参数: a = 7038.3745, b = 143.8489, c = 1705.0000\n",
      "2024-12-14 00:06:37,378 - root - INFO - --------------------------------------------------\n",
      "2024-12-14 00:06:37,379 - root - INFO - 开始执行动态指数拟合：N_969...\n",
      "2024-12-14 00:06:37,379 - root - INFO - 开始清洗数据...\n",
      "2024-12-14 00:06:37,380 - root - INFO - 数据清洗完成：原始数据点 1724 个，清洗后数据点 401 个。\n",
      "2024-12-14 00:06:37,381 - __main__ - INFO - 开始动态指数拟合...\n",
      " - 初始拟合点数: 10  - 最小 R²: 0.90  - 最大迭代次数: 100\n",
      "2024-12-14 00:06:37,381 - __main__ - DEBUG - 拟合迭代 1: 使用数据点 391 到 401（共 10 个点）\n",
      "2024-12-14 00:06:37,416 - __main__ - DEBUG - 拟合结果：参数=[2.34442295e-05 9.53861831e-01 1.41606398e+02], R²=0.1765\n",
      "2024-12-14 00:06:37,417 - __main__ - INFO - 拟合成功，R²=0.1765，使用数据点 391 到 401\n",
      "2024-12-14 00:06:37,418 - __main__ - ERROR - 拟合过程中发生未预料的错误: local variable 'new_t_fit' referenced before assignment\n",
      "2024-12-14 00:06:37,418 - root - ERROR - 拟合失败。\n",
      "2024-12-14 00:06:37,420 - root - INFO - --------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_exponential_fit\\N_9146-1704_1724.png\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 配置日志记录（如上）\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.StreamHandler()           # 同时输出到控制台\n",
    "        ]\n",
    "    )\n",
    "    # 初始化 FittingModule 实例\n",
    "    config = load_config(\"C:\\\\Users\\\\husky\\\\Desktop\\\\peek-find\\\\PEM4Fe\\\\data\\\\config.yaml\")  # 或者 \"config.json\"\n",
    "    fitting_module = FittingModule(config=config)\n",
    "    logging.info(\"FittingModule 实例已初始化。\")\n",
    "\n",
    "    # 提取时间序列和数据序列\n",
    "    t = collected_data['t']\n",
    "\n",
    "    for col in collected_data.columns[1:]:  # 从第2列到结束\n",
    "        N = collected_data[col]  # 确保 'N' 列名正确\n",
    "        index = str(col)\n",
    "        logging.info(f\"开始执行动态指数拟合：{col}...\")\n",
    "        # 去除无效值\n",
    "        t_clean, N_clean = clean_data(t, N)\n",
    "        fit_result = fitting_module.fit_dynamic(t_clean, N_clean, index)\n",
    "        \n",
    "        if fit_result:\n",
    "            params = fit_result['params']\n",
    "            r_squared = fit_result['r_squared']\n",
    "            logging.info(f\"拟合成功。R² = {r_squared:.4f}\")\n",
    "            logging.info(f\"拟合参数: a = {params[0]:.4f}, b = {params[1]:.4f}, c = {params[2]:.4f}\")\n",
    "        else:\n",
    "            logging.error(\"拟合失败。\")\n",
    "        logging.info(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- 峰值检测模块 -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- 峰值检测模块 -------------------------- #\n",
    "class PeakDetectionModule:\n",
    "    \"\"\"峰值检测模块\"\"\"\n",
    "    def detect_peaks(self, N, Nsc, width_threshold=5):\n",
    "        \"\"\"检测数据中的峰值\"\"\"\n",
    "        pass\n",
    "\n",
    "    def find_nearest_interval(self, N, N_forecast, Nsc):\n",
    "        \"\"\"寻找密集区域区间\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- 可视化模块 -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- 可视化模块 -------------------------- #\n",
    "class VisualizationModule:\n",
    "    \"\"\"可视化模块\"\"\"\n",
    "    def plot_analysis_figure(self, t, N, fit_result, peaks_info, Nsc, N0, column_name, output_dir):\n",
    "        \"\"\"绘制单列数据分析图\"\"\"\n",
    "        pass\n",
    "\n",
    "    def plot_overall_analysis(self, results, output_dir):\n",
    "        \"\"\"绘制总体分析图\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- 结果输出模块 -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- 结果输出模块 -------------------------- #\n",
    "def save_results_to_csv(results, output_file):\n",
    "    \"\"\"保存分析结果到 CSV 文件\"\"\"\n",
    "    pass\n",
    "\n",
    "def save_summary_to_log(results, log_file):\n",
    "    \"\"\"保存总结到日志文件\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- 主逻辑模块 -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- 主逻辑模块 -------------------------- #\n",
    "def process_column(column, t_clean, N_clean, Nsc, N0, output_dir, fitting_module, peak_module, viz_module):\n",
    "    \"\"\"\n",
    "    处理单列数据：\n",
    "    - 数据清洗\n",
    "    - 拟合分析\n",
    "    - 峰值检测\n",
    "    - 结果可视化\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def main(config_file):\n",
    "    \"\"\"\n",
    "    主程序入口：\n",
    "    - 加载配置与参数\n",
    "    - 数据处理与分析\n",
    "    - 结果保存与输出\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- 脚本入口 -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:05:55,127 - root - INFO - 日志文件保存路径: ./logs\\app.log\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- 脚本入口 -------------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载日志\n",
    "    setup_logging()\n",
    "    \n",
    "    # 加载配置和参数\n",
    "    config_file = \"config.json\"  # 默认配置文件路径\n",
    "    main(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
